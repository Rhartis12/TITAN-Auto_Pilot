import pandas as pd
import numpy as np
import yfinance as yf
import requests
from scipy.stats import spearmanr
import os
import warnings
import json
import FinanceDataReader as fdr
from datetime import datetime
import time # sleepÏö©

warnings.filterwarnings("ignore")

# ============================================================
# 1. USER CONFIG
# ============================================================
START_DATE = "2000-01-01"
REBAL_FREQ = "ME"
ECOS_KEY = os.getenv("ECOS_KEY", "N671R802ZP944AEQ5J53") 
CACHE_FILE = "krx_yfinance_cache.pkl"

# Îß§ÌÅ¨Î°ú Î∞è Ï†ÑÎûµ ÏÑ§Ï†ï
Z_WINDOW = 36
Z_THRESH = 0.5
TOP_PCT = 0.2

# ÌÖîÎ†àÍ∑∏Îû® ÏÑ§Ï†ï
TG_TOKEN = os.getenv("TG_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")

print("üöÄ Titan V7.7 (KOSPI) Started...")

# ============================================================
# 2. MACRO DATA LOADING (ECOS)
# ============================================================
def fetch_ecos_long(stat_code, item_code, start_date):
    full_series = []
    periods = [("200001", "200912"), ("201001", "201912"), ("202001", "202612")]
    if start_date < "200001":
        periods.insert(0, ("198001", "199912"))

    for s, e in periods:
        url = f"https://ecos.bok.or.kr/api/StatisticSearch/{ECOS_KEY}/json/kr/1/500/{stat_code}/M/{s}/{e}/{item_code}/"
        try:
            res = requests.get(url).json()
            if 'StatisticSearch' in res:
                df = pd.DataFrame(res['StatisticSearch']['row'])
                full_series.append(df)
        except: continue

    if not full_series: return pd.Series(dtype=float)

    final_df = pd.concat(full_series)
    final_df['DATE'] = pd.to_datetime(final_df['TIME'], format='%Y%m') + pd.offsets.MonthEnd(0)
    final_df['VALUE'] = pd.to_numeric(final_df['DATA_VALUE'])
    return final_df.drop_duplicates('DATE').set_index('DATE')['VALUE'].sort_index()

rate_series = fetch_ecos_long("721Y001", "5050000", "200001")
cpi_series = fetch_ecos_long("901Y009", "0", "198001")

# ============================================================
# 3. PRICE & SECTOR LOADING (Modified)
# ============================================================
print("üîÑ Loading Stock Data...")

# 1. KRX Ï†ÑÏ≤¥ Î¶¨Ïä§Ìä∏ Ï°∞Ìöå (Ï¢ÖÎ™©Î™Ö Îß§ÌïëÏö©)
try:
    df_krx = fdr.StockListing('KRX')
    # 'Ìã∞Ïª§:Ï¢ÖÎ™©Î™Ö' ÎîïÏÖîÎÑàÎ¶¨ (Ïòà: '005930': 'ÏÇºÏÑ±Ï†ÑÏûê')
    NAME_MAP = df_krx.set_index('Code')['Name'].to_dict()
    # FDR ÏÑπÌÑ∞ Ï†ïÎ≥¥ Î∞±ÏóÖ (yfinance Ïã§Ìå® Ïãú ÏµúÌõÑÏùò ÏàòÎã®)
    fdr_sectors = df_krx.set_index('Code')['Sector'].to_dict()
except Exception as e:
    print(f"‚ö†Ô∏è KRX Listing Error: {e}")
    NAME_MAP = {}
    fdr_sectors = {}

# 2. KOSPI ÏãúÏ¥ù ÏÉÅÏúÑ 200Í∞ú ÏÑ†Ï†ï (FDR ÏÇ¨Ïö©)
# KOSPI Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏúºÎ©¥ Ï†ÑÏ≤¥ÏóêÏÑú ÌïÑÌÑ∞ÎßÅ
df_kospi = df_krx[df_krx['Market'] == 'KOSPI'].sort_values('Marcap', ascending=False).head(200)
tickers = [f"{code}.KS" for code in df_kospi['Code']]

# [ÏàòÏ†ï] yfinance ÏÑπÌÑ∞ Í∞ïÏ†ú Ï°∞Ìöå Î°úÏßÅ
print(f"   - Fetching Sectors for {len(tickers)} tickers from yfinance...")
sector_map = {}

for i, t in enumerate(tickers):
    pure_code = t.replace('.KS', '')
    
    # 1ÏàúÏúÑ: yfinance (Í∏ÄÎ°úÎ≤å ÌëúÏ§Ä ÏÑπÌÑ∞Î™Ö)
    yf_sector = None
    try:
        ticker_obj = yf.Ticker(t)
        # fast_infoÎäî ÎÑ§Ìä∏ÏõåÌÅ¨ ÏöîÏ≤≠ÏùÑ Ï§ÑÏù¥Í≥† Îçî Îπ†Î¶Ñ (ÏµúÏã† yfinance Í∏∞Îä•)
        # ÌïòÏßÄÎßå ÏÑπÌÑ∞ Ï†ïÎ≥¥Îäî Ïó¨Ï†ÑÌûà .infoÏóê ÏûàÏùÑ Ïàò ÏûàÏùå. Ïö∞ÏÑ†ÏàúÏúÑ Ï≤¥ÌÅ¨.
        
        # 1. .info Ï†ëÍ∑º (ÎÑ§Ìä∏ÏõåÌÅ¨ ÏöîÏ≤≠ Î∞úÏÉù)
        info = ticker_obj.info
        yf_sector = info.get('sector')
        
    except Exception:
        yf_sector = None

    # 2. Í≤∞Í≥º Ï≤òÎ¶¨
    if yf_sector and yf_sector != "Unknown":
        # yfinance ÏÑ±Í≥µ
        sector_map[t] = yf_sector
        # Î°úÍ∑∏Í∞Ä ÎÑàÎ¨¥ ÎßéÏúºÎ©¥ Ï£ºÏÑù Ï≤òÎ¶¨ÌïòÏÑ∏Ïöî
        # print(f"     [YF] {t}: {yf_sector}") 
    else:
        # yfinance Ïã§Ìå® Ïãú -> FDR Ï†ïÎ≥¥ ÏÇ¨Ïö© (Î∞±ÏóÖ)
        fdr_sec = fdr_sectors.get(pure_code, 'Unknown')
        sector_map[t] = fdr_sec
        print(f"     ‚ö†Ô∏è [FDR Fallback] {t}: YF failed -> Using {fdr_sec}")

    # Ï∞®Îã® Î∞©ÏßÄ ÎîúÎ†àÏù¥ (yfinance Ïó∞ÏÜç Ìò∏Ï∂ú Ïãú ÌïÑÏàò)
    if i % 10 == 0: 
        print(f"     ... Processed {i}/{len(tickers)}")
    time.sleep(0.2) # ÎîúÎ†àÏù¥Î•º Ï°∞Í∏à Îçî Ï£ºÏñ¥(0.2Ï¥à) ÏïàÏ†ïÏÑ± ÌôïÎ≥¥


# Price Download
price = yf.download(tickers, start=START_DATE, progress=False)['Close']
if isinstance(price.columns, pd.MultiIndex):
    price.columns = price.columns.get_level_values(-1)

price = price.resample(REBAL_FREQ).last().ffill()
ret = price.pct_change()

# Macro Align
rate = rate_series.reindex(price.index).ffill()
cpi = cpi_series.pct_change(12).reindex(price.index).ffill()

macro_raw = pd.concat([rate, cpi], axis=1).ffill()
macro_raw.columns = ["RATE", "CPI"]
macro_z = (macro_raw - macro_raw.rolling(Z_WINDOW).mean()) / macro_raw.rolling(Z_WINDOW).std()
macro_z = macro_z.fillna(0)

# ============================================================
# 4. STRATEGY ENGINE
# ============================================================
print("‚öôÔ∏è Calculating Factors...")

sectors = list(set(sector_map.values()))
raw_val = 1 / price
value_z = pd.DataFrame(np.nan, index=raw_val.index, columns=raw_val.columns)

# ÏµúÍ∑º 1ÎÖÑÏπòÎßå Í≥ÑÏÇ∞ (ÏÜçÎèÑ ÏµúÏ†ÅÌôî)
for dt in raw_val.index[-13:]:
    for s in sectors:
        codes = [c for c, sec in sector_map.items() if sec == s and c in raw_val.columns]
        if len(codes) > 2:
            row = raw_val.loc[dt, codes]
            value_z.loc[dt, codes] = (row - row.mean()) / (row.std() if row.std() > 0 else 1)

FACTORS = {
    "VALUE": value_z.fillna(0),
    "MOM": (price.pct_change(12) - price.pct_change(1)).fillna(0),
    "LOWVOL": (-ret.rolling(12).std()).fillna(0),
    "QUALITY": (ret.rolling(12).mean() / ret.rolling(12).std()).fillna(0)
}

# IC & Weights
ic_raw = {}
for name, f_df in FACTORS.items():
    res = []
    rk = f_df.rank(axis=1, pct=True)
    for t in range(len(rk) - 1):
        x, y = rk.iloc[t], ret.iloc[t + 1]
        mask = x.notna() & y.notna()
        res.append(spearmanr(x[mask], y[mask])[0] if mask.sum() > 10 else 0)
    ic_raw[name] = pd.Series(res, index=rk.index[:-1])

ic_df = pd.DataFrame(ic_raw).rolling(12).mean().fillna(0)
mult = pd.DataFrame(1.0, index=ic_df.index, columns=ic_df.columns)

for t in mult.index:
    try:
        r_z, c_z = macro_z.loc[t, "RATE"], macro_z.loc[t, "CPI"]
        if (r_z > Z_THRESH) and (c_z > Z_THRESH): 
            mult.loc[t, "MOM"] = 0.0
            mult.loc[t, ["VALUE", "LOWVOL", "QUALITY"]] *= 1.5
        elif (r_z < -Z_THRESH): 
            mult.loc[t, ["MOM", "VALUE"]] *= 0.5
            mult.loc[t, ["QUALITY", "LOWVOL"]] *= 1.8
    except: continue

w_final = (ic_df * mult).clip(lower=0)
w_final = w_final.div(w_final.sum(axis=1).replace(0, 1), axis=0)
w_final = w_final.reindex(ret.index).ffill() # Forward Fill for Live

# ============================================================
# 5. LIVE SELECTION & JSON GEN
# ============================================================
print("üíæ Generating Live Data...")

last_idx = price.index[-1]
latest_weights = w_final.iloc[-1]

final_score_series = pd.Series(0.0, index=price.columns)
for name in FACTORS:
    val_series = FACTORS[name].iloc[-1]
    valid_rank = val_series.rank(pct=True, ascending=True).fillna(0.5)
    weight = latest_weights[name]
    final_score_series += valid_rank * weight

# ÏÉÅÏúÑ Ï¢ÖÎ™© ÏÑ†Ï†ï
candidates = final_score_series.sort_values(ascending=False).head(int(len(final_score_series) * TOP_PCT))
latest_prices = price.iloc[-1]

# Buy List DF
buy_list = pd.DataFrame({
    'Ticker': candidates.index,
    'Score': candidates.values,
    'Sector': [sector_map.get(t, 'Unknown') for t in candidates.index],
    'Price': [latest_prices.get(t, 0) for t in candidates.index],
    'Weight': [1.0/len(candidates)] * len(candidates) 
})

# JSON ÏÉùÏÑ± (ÎåÄÏãúÎ≥¥ÎìúÏö©)
last_r, last_c = macro_z.iloc[-1]['RATE'], macro_z.iloc[-1]['CPI']
regime = "Normal"
if (last_r > Z_THRESH) and (last_c > Z_THRESH): regime = "Stagflation"
elif (last_r < -Z_THRESH): regime = "Recession"
elif (last_r > Z_THRESH) and (last_c < 0): regime = "Overheat"

web_data = {
    "date": last_idx.strftime('%Y-%m-%d'),
    "regime": {"status": regime, "rate_z": round(last_r, 2), "cpi_z": round(last_c, 2)},
    "weights": latest_weights.to_dict(),
    "portfolio": []
}

for _, row in buy_list.iterrows():
    web_data["portfolio"].append({
        "ticker": row['Ticker'].replace(".KS", ""),
        "sector": row['Sector'],
        "price": row['Price'],
        "weight": row['Weight']
    })

# JSON Ï†ÄÏû• (ÌïúÍµ≠Ïö© ÌååÏùºÎ™Ö: dashboard_data_kr.json)
with open("dashboard_data_kr.json", "w", encoding='utf-8') as f:
    json.dump(web_data, f, indent=4, ensure_ascii=False)

print("‚úÖ KR Dashboard JSON Saved.")

# ÌÖîÎ†àÍ∑∏Îû® Ï†ÑÏÜ°
if TG_TOKEN and TG_CHAT_ID:
    msg = f"üá∞üá∑ Titan V7.7 KOSPI Update\nRegime: {regime}\nTop Pick: {buy_list.iloc[0]['Ticker']}"
    requests.post(f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage", data={"chat_id": TG_CHAT_ID, "text": msg})
